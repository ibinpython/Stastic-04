**线性回归（Linear Regression**）:

对于一个的拥有mm个观测的训练数据集XX而言，回归的目的就是要对新的nn维输入xx，预测其对应的一个或者多个目标输出tt。

线性回归模型的基本特性就是：模型是参数的线性函数。

最简单的线性回归模型当然是模型是参数的线性函数的同时，也是输入变量的线性函数，或者叫做线性组合。

如果我们想要获得更为强大的线性模型，可以通过使用一些输入向量xx的基函数f(x)f(x)的线性组合来构建一个线性模型。这种模型，由于它是参数的线性函数，所以其数学分析相对较为简单，同时可以是输入变量的非线性函数。

从概率的角度来说，回归模型就是估计一个条件概率分布：p(t|x)p(t|x)。因为这个分布可以反映出模型对每一个预测值tt关于对应的xx的不确定性。基于这个条件概率分布对输入xx估计其对应的tt的过程，就是最小化损失函数（loss function）的期望的过程。

对于线性模型而言，一般所选择的损失函数是平方损失。

由于模型是线性的，所以在模式识别和机器学习的实际应用中存在非常大的局限性，特别是当输入向量的维度特别高的时候，其局限性就更为明显。但同时，线性模型在数学分析上相对较为简单，进而成为了很多其他的复杂算法的基础。



# 卡方分布

- 定义
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190201212850933.jpg)
- 概率密度函数
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190201213026480.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RldmN5,size_16,color_FFFFFF,t_70)

# 卡方检验

![img](https://img-blog.csdnimg.cn/20190201212909814.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RldmN5,size_16,color_FFFFFF,t_70)

**方差分析的基本思想和原理**:
为分析分类型自变量对数值型因变量的影响，需要从数据误差来源分析。 
(1) 图形描述 
(2) 误差分解 
思想：通过对数据误差来源的分析来判断不同总体的均值是否相等，进而分析自变量对因变量是否有显著影响。 
组内误差：同一总体下，观测值的差异，反映了一个样本内部数据的离散程度。只含随机误差。 
组间误差：不同总体之间的差异，反映了不同样本间的离散程度。是随机误差和系统误差的总和。 
总平方和：反映全部数据误差大小的平方和，反映了全部观察值的离散状况。 
总平方和（SST）=组内平方和（SSE）+组间平方和（SSA） 
组内平方和也称误差平方和或残差平方和 
组间平方和也称因素平方和 
(3) 误差分析 

以上例为例，如果不同行业对投诉次数没有影响，那么在组间误差中只包含随机误差，而没有组内误差，这时组间误差与组内误差经过平均后的数值就会接近1:1，反之，组间误差与组内误差的比值会大于1，当比值达到一定程度时，因素的不同水平之间即存在显著差异。



参考：https://blog.csdn.net/devcy/article/details/86741215